\section{Testing}

Testing of the implementation was done on Hardisc\footnote{\url{https://github.com/janomach/the-hardisc}} (simulated using ModelSim) - a hardened RISC-V core with the ability to statically insert faults during runtime of the program. The form of the fault is a single bit-flip. The frequency of the fault insertion as well as the regions where fault are inserted can be changed to simulate different environments and circumstances. For the purpose of narrowing down the scope of the thesis, faults were only inserted in the following regions:

\textbf{General Purpose Registers} (GPR)
Registers used for general computation or temporary storage during instruction execution.

\textbf{Register File Control} (RFC)
Controls access to the register file; involved in reading/writing registers.

\textbf{Arithmetic Logic Unit} (ALU)
The part of the CPU that performs arithmetic and logical operations.

\textbf{Multiply-Divide Unit} (MDU)
Specialized unit for performing multiplication and division operations.

\textbf{Data Path} (DP)
The part of the CPU where data is processed, including registers, ALUs, and buses.

\textbf{Trap Interrupt Registers} (TP)
Handles traps (exceptions) and interrupts in the CPU.

Notably, RAM was exempt from fault insertions during our testing. Should a non-transient error occur in the part of RAM which holds the program instructions there would be no way to properly recover from it using software-only fault tolerance. Usually, RAM and CPU duplication is used, effectively running the same program twice in parallel with set synchronization points. This method is outside of the scope of software implemented fault tolerance.

The methods outlined in the implementation section, however, are in theory capable of detecting and recovering from certain faults in RAM. As mentioned in section \ref{sec:checksum}, checksums are capable of detecting corruption in variables, this includes variables stored in the RAM. Similarly, using multiversion programming can provide tolerance even in the case of non-transient error occuring in one of the versions. Due to general unreliability of this approach, however, the testing on RAM fault insertions was not conducted.

\subsection{Fault coverage}

TODO: Add stats for protected vs unproteced execution results

\subsection{Performance impact}

Performance impact of the implemneted fault-tolerance methods was measured without employing any compiler optimizations on a fault-free version of the simulated core. In the presence of faults, the effective performance could vary unexpected, influenced by the randomness of the fault insertion. As such, there is not much point in measuring performance in the presence of faults.

The test were measured in CPU cycles using the RISC-V \textit{mcycle} and \textit{mcycleh} registers.

\begin{table}[h]
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Test} & \textbf{Unprotected (cycles)} & \textbf{Protected (cycles)} & \textbf{Increase (\%)} \\
\hline
Fibonacci sequence & 30734 & 34983 & 13.82\% \\
Matrix dot product & 9871 & 11133 & 12.78\% \\
Nested function calls & 9889 & 13126 & 32.73\% \\
Bubblesort & 15228 & 16773 & 10.14\% \\
CRC calculation & 8278 & 10614 & 28.21\% \\
\hline
\end{tabular}
}
\caption{Execution time comparison between unprotected and protected tests}
\label{tab:time_increase}
\end{table}

As expected, looking at Table \ref{tab:time_increase} we see an increase in CPU cycles it takes to execute the protected version as opposed to the unprotected one. Fibonacci, Matrix and Bubblesort (group one) test only incurred rougly 12\% increase, while both "Nested function calls" and CRC (group two) incurred much more substantial increase. The main difference between these two groups of tests is their flow graph complexity. Group one has linear control flow and mostly consists of 1-4 function call, meaning very little time is spent on CFCSS checking. Group two has more complex control flow resulting in a lot of CFCSS checks.

Comparing the results of select tests without CFCSS (Table \ref{tab:cfcss_nocfcss}), we can deduce several things. The additional CPU cycles needed for checkpoint and multiversion protection is between 1000 and 1500 cycles. This is a constant increase and should not scale with the control flow complexity or instruction size of the tests. The CFCSS 

\begin{table}[h]
\centering
% \resizebox{\linewidth}{!}{%
\begin{tabular}{|l|c|c|}
\hline
\textbf{Test} & \textbf{With CFCSS} & \textbf{Without CFCSS} \\
\hline
Fibonacci sequence & 34983 & 31881 \\
Nested function calls & 13126 & 11828 \\
CRC calculation & 10614 & 8746 \\

\hline
\end{tabular}
% }
\caption{Protected fibonacci test with and without CFCSS}
\label{tab:cfcss_nocfcss}
\end{table}