\section{Testing}

Testing of the implementation was done on Hardisc\footnote{\url{https://github.com/janomach/the-hardisc}} (simulated using ModelSim) - a hardened RISC-V core with the ability to statically insert faults during runtime of the program. The form of the fault is a single bit-flip. The frequency of the fault insertion as well as the regions where fault are inserted can be changed to simulate different environments and circumstances. For the purpose of narrowing down the scope of the thesis, faults were only inserted in the following regions:

\textbf{General Purpose Registers} (GPR)
Registers used for general computation or temporary storage during instruction execution.

\textbf{Register File Control} (RFC)
Controls access to the register file; involved in reading/writing registers.

\textbf{Arithmetic Logic Unit} (ALU)
The part of the CPU that performs arithmetic and logical operations.

\textbf{Multiply-Divide Unit} (MDU)
Specialized unit for performing multiplication and division operations.

\textbf{Data Path} (DP)
The part of the CPU where data is processed, including registers, ALUs, and buses.

\textbf{Trap Interrupt Registers} (TP)
Handles traps (exceptions) and interrupts in the CPU.

Notably, RAM was exempt from fault insertions during our testing. Should a non-transient error occur in the part of RAM which holds the program instructions there would be no way to properly recover from it using software-only fault tolerance. Usually, RAM and CPU duplication is used, effectively running the same program twice in parallel with set synchronization points. This method is outside of the scope of software implemented fault tolerance.

The methods outlined in the implementation section, however, are in theory capable of detecting and recovering from certain faults in RAM. As mentioned in section \ref{sec:checksum}, checksums are capable of detecting corruption in variables, this includes variables stored in the RAM. Similarly, using multiversion programming can provide tolerance even in the case of non-transient error occuring in one of the versions. Due to general unreliability of this approach, however, the testing on RAM fault insertions was not conducted.

\subsection{Benchmarks}

A set of benchmarks was selected to evaluate the effectiveness of the implemented fault tolerance techniques. These benchmarks primarily consist of common arithmetic operations and data manipulation tasks representative of typical embedded system workloads. 

In addition to standard benchmarks, one unique benchmark - \textit{Nested Function Calls} (NFC) was included. This benchmark involves a series of functions invoking one another in a nested manner, creating intertwined control-flow graph. It was specifically chosen to assess the performance impact of CFCSS, which is particularly sensitive to complex function call hierarchies.

Benchmark programs report results in one of two ways, successful execution (0) and unrecoverable error (1). Any other return status code is considered an unknown error. The reliability of the fault tolerance was measured as a sum of successful executions and correctly reported unrecoverable errors divided by the overall number of executions (25 per benchmark). Each benchmark was given equal amount of time to execute (100 000 CPU cycles), if the time thresholdt is reached the program ends in a timeout. Notably, a timeout does not necessarily means the benchmark itself did not execute correctly. It is very common for the FreeRTOS scheduler to be the source of an error leading to a timeout. As such, in the case of a timeout, the output logs are examined to determine if the benchmark succeeded.

\begin{table}[h]
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Fib sequence} & \textbf{Correct} & \textbf{Errors Reported} & \textbf{Fault tolerance} & \textbf{Timeouts} \\
\hline
Unprotected & 10 & 5 & 60\% & 8 \\
Protected & 14 & 9 & 92\% & 3 \\
\hline
\end{tabular}
}
\caption{Fibonacci sequence benchmark statistics}
\label{tab:fib_bench}
\end{table}

As seen in Table \ref{tab:fib_bench} the overall fault tolerance of the protected benchmark went up significantly. The increase in correct results was not exceptionally high likely due to the fact that errors mostly occurred outside of the variables and registers that would directly alter the computation result. Rather, most faults resulted in errors manifesting in various supporting subroutines. Evidence of this is the nearly doubled number of reported errors when fault tolerance was enabled.

\begin{table}[h]
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{|l|c|c|c|c|}
\hline
\textbf{Matrix dot product} & \textbf{Correct} & \textbf{Errors Reported} & \textbf{Fault tolerance} & \textbf{Timeouts} \\
\hline
Unprotected & 16 & 0 & 64\% & 9 \\
Protected & 18 & 7 & 100\% & 0 \\
\hline
\end{tabular}
}
\caption{Matrix multiplication benchmark statistics}
\label{tab:matrix_bench}
\end{table}

Similar trend can be observed in the case of Matrix benchmark (see Table \ref{tab:matrix_bench}). The correct results difference is even lower, likley due to the fact that the matrix dot product test requires less CPU instructions, and therefore is a relatively smaller area for faults to manifest. However, the overall error reporting went up significantly, proving our fault tolerance methods are good at catching error that would otherwise result in unexepcted program termination.

\subsection{Performance impact}

Performance impact of the implemneted fault-tolerance methods was measured without employing any compiler optimizations on a fault-free version of the simulated core. In the presence of faults, the effective performance could vary unexpected, influenced by the randomness of the fault insertion. As such, there is not much point in measuring performance in the presence of faults.

The test were measured in CPU cycles using the RISC-V \textit{mcycle} and \textit{mcycleh} registers.

\begin{table}[h]
\centering
\resizebox{\linewidth}{!}{%
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Test} & \textbf{Unprotected (cycles)} & \textbf{Protected (cycles)} & \textbf{Increase (\%)} \\
\hline
Fibonacci & 30734 & 34983 & 13.82\% \\
Matrix & 9871 & 11133 & 12.78\% \\
NFC & 9889 & 13126 & 32.73\% \\
Bubblesort & 15228 & 16773 & 10.14\% \\
CRC & 8278 & 10614 & 28.21\% \\
\hline
\end{tabular}
}
\caption{Execution time comparison between unprotected and protected tests}
\label{tab:time_increase}
\end{table}

As expected, looking at Table \ref{tab:time_increase} we see an increase in CPU cycles it takes to execute the protected version as opposed to the unprotected one. Fibonacci, Matrix and Bubblesort (group one) test only incurred rougly 12\% increase, while both "Nested function calls" and CRC (group two) incurred much more substantial increase. The main difference between these two groups of tests is their flow graph complexity. Group one has linear control flow and mostly consists of 1-4 function call, meaning very little time is spent on CFCSS checking. Group two has more complex control flow resulting in a lot of CFCSS checks.

Comparing the results of select tests without CFCSS (Table \ref{tab:cfcss_nocfcss}), we can deduce several things. The additional CPU cycles needed for checkpoint and multiversion protection is between 1000 and 1500 cycles. This is a constant increase and should not scale with the control flow complexity or instruction size of the tests. The CFCSS 

\begin{table}[h]
\centering
% \resizebox{\linewidth}{!}{%
\begin{tabular}{|l|c|c|}
\hline
\textbf{Test} & \textbf{With CFCSS} & \textbf{Without CFCSS} \\
\hline
Fibonacci sequence & 34983 & 31881 \\
Nested function calls & 13126 & 11828 \\
CRC calculation & 10614 & 8746 \\

\hline
\end{tabular}
% }
\caption{Protected fibonacci test with and without CFCSS}
\label{tab:cfcss_nocfcss}
\end{table}

\subsection{Size Impact}

To evaluate the memory overhead introduced by the fault tolerance mechanisms, we compared the size of the compiled binaries with and without protection under two conditions: with no compiler optimizations and with standard release optimizations enabled. As expected, enabling protection introduces additional instructions and data structures, resulting in larger binary sizes. The impact is more pronounced in the unoptimized build, while optimized builds show a more moderate increase due to compiler optimizations reducing overall code size.

\begin{table}[!h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Compiler optimizations?} & \textbf{Unprotected} & \textbf{Protected} & \textbf{Size increase} \\
\hline
NO  & 23164 & 32847 & 41.8\% \\
YES & 8467 & 9216 & 8.84\% \\
\hline
\end{tabular}
\caption{Binary size increase with and without protection}
\end{table}

